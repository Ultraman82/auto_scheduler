{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reference_number', 'item_description', 'product_family',\n",
       "       'product_model', 'product_length', 'order_quantity', 'y', 'steps',\n",
       "       'B0010', 'C0060', 'C0080', 'C0090', 'D0010', 'D0020', 'F0010', 'C0010',\n",
       "       'C0020', 'K0010', 'K0020', 'B0020', 'B0021', 'B0025', 'B0060', 'B0090',\n",
       "       'B0050', 'B0080', 'C0075', 'J0020', 'K0011', 'C0070', 'C0100', 'C0110',\n",
       "       'B0012', 'B0015', 'B0040', 'B0070', 'C0120', 'H0010', 'H0020', 'H0030',\n",
       "       'H0070', 'J0050', 'J0060', 'C0040', 'B0062', 'C0050', 'B0030', 'C0030',\n",
       "       'C0031', 'C0035', 'K0030', 'H0046', 'GL010', 'GL130', 'GL140', 'H0045',\n",
       "       'H0060', 'H0050', 'F0020', 'J0025', 'GL030', 'H0051', '0010',\n",
       "       'release_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "cols = ['product_family', 'product_model','B0012', 'B0015', 'B0021', 'B0025', 'B0030', 'B0040', 'B0050', 'B0060', 'B0070', 'B0080', 'C0020', 'C0030', 'C0031', 'C0035', 'C0040', 'C0050', 'C0060', 'C0070', 'C0075', 'C0080', 'C0090', 'C0100', 'C0110',\n",
    "        'C0120', 'D0010', 'D0020', 'F0010', 'F0020', 'GL010', 'GL030', 'GL130', 'GL140', 'H0010', 'H0020', 'H0030', 'H0045', 'H0046', 'H0050', 'H0051', 'H0060', 'H0070', 'J0020', 'J0025', 'J0050', 'J0060', 'K0010', 'K0011', 'K0020', 'steps', 'y']\n",
    "# logs = pd.read_csv(\"./vip_weekend2.csv\")\n",
    "logs = pd.read_parquet('general_throttled.parquet')\n",
    "logs.columns\n",
    "logs.set_index('order_number', inplace=True)\n",
    "logs=logs[cols]\n",
    "# logs.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs.fillna(0, inplace=True)\n",
    "map_ = {}\n",
    "ans_cols = ['product_family', 'product_model', 'key', 'arr']\n",
    "family_factor = ['HCR', 'HDR', 'HRW', 'HSR',\n",
    "                 'SHS', 'SHW', 'SR', 'SRS', 'SRS-W']\n",
    "model_factor = ['12', '15', '15/300R', '17', '20', '21', '25',\n",
    "                '27', '30', '35', '45', '45/800R', '55', '65', '9', '9X']\n",
    "map_ = {}\n",
    "for row in zip(*logs.to_dict(\"list\").values()):\n",
    "    family = row[0]\n",
    "    model = row[1]    \n",
    "    arr = np.array(row[2:-2])\n",
    "    index= np.where(arr > 0)[0]\n",
    "    index_str = str(index)\n",
    "    if index_str in map_.keys():\n",
    "        map_[index_str] = np.append(map_[index_str], [arr[index]], axis=0)\n",
    "    else:\n",
    "        map_[index_str] = np.zeros((0,len(index)), dtype=int)\n",
    "        map_[index_str] = np.append(map_[index_str], [arr[index]], axis=0)\n",
    "map_answer = {}\n",
    "for key in map_.keys():\n",
    "    map_answer[key] = np.mean(map_[key], axis=0)\n",
    "    sum = map_answer[key].sum()\n",
    "    map_answer[key] = list(map_answer[key] / sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs.fillna(0, inplace=True)\n",
    "map_ = {}\n",
    "ans_cols = ['product_family', 'product_model', 'key', 'arr']\n",
    "family_factor = ['HCR', 'HDR', 'HRW', 'HSR',\n",
    "                 'SHS', 'SHW', 'SR', 'SRS', 'SRS-W']\n",
    "model_factor = ['12', '15', '15/300R', '17', '20', '21', '25',\n",
    "                '27', '30', '35', '45', '45/800R', '55', '65', '9', '9X']\n",
    "map_ = {}\n",
    "for row in zip(*logs.to_dict(\"list\").values()):\n",
    "    family = row[0]\n",
    "    model = row[1]    \n",
    "    arr = np.array(row[2:-2])\n",
    "    index= np.where(arr > 0)[0]\n",
    "    index_str = str(index)\n",
    "    if index_str in map_.keys():\n",
    "        map_[index_str] = np.append(map_[index_str], [arr[index]], axis=0)\n",
    "    else:\n",
    "        map_[index_str] = np.zeros((0,len(index)), dtype=int)\n",
    "        map_[index_str] = np.append(map_[index_str], [arr[index]], axis=0)\n",
    "map_answer = {}\n",
    "for key in map_.keys():\n",
    "    map_answer[key] = np.mean(map_[key], axis=0)\n",
    "    sum = map_answer[key].sum()\n",
    "    map_answer[key] = list(map_answer[key] / sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(map_answer)\n",
    "import json\n",
    "with open(\"staget_mapper2.json\", \"w\") as outfile:\n",
    "    json.dump(map_answer, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = ['item_description','product_family', 'product_model', 'product_length',\n",
    "'order_quantity', 'D0010', 'D0020', 'F0010', 'C0010',\n",
    "'C0020', 'C0060', 'C0080', 'C0090', 'K0010', 'K0020', 'B0010', 'B0020',\n",
    "'B0021', 'B0025', 'B0060', 'B0080', 'C0075', 'J0020', 'K0011', 'C0070',\n",
    "'C0100', 'C0110', 'C0120', 'H0010', 'H0020', 'H0030', 'H0070', 'J0050',\n",
    "'J0060', 'B0012', 'B0040', 'B0070', 'C0040', 'B0062', 'C0050', 'C0030',\n",
    "'C0031', 'C0035', 'H0046', 'GL010', 'GL130', 'GL140', 'B0050', 'H0045',\n",
    "'H0060', 'H0050', 'B0030', 'F0020', 'J0025', 'B0015', 'GL030', 'H0051', 'total_steps', 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.drop(columns=['item_description', 'product_family'], inplace=True)\n",
    "last_cols = ['product_model', 'product_length', 'order_quantity', 'D0010', 'D0020',\n",
    "       'F0010', 'C0010', 'C0020', 'C0060', 'C0080', 'C0090', 'K0010', 'K0020',\n",
    "       'B0010', 'B0020', 'B0021', 'B0025', 'B0060', 'B0080', 'C0075', 'J0020',\n",
    "       'K0011', 'C0070', 'C0100', 'C0110', 'C0120', 'H0010', 'H0020', 'H0030',\n",
    "       'H0070', 'J0050', 'J0060', 'B0012', 'B0040', 'B0070', 'C0040', 'B0062',\n",
    "       'C0050', 'C0030', 'C0031', 'C0035', 'H0046', 'GL010', 'GL130', 'GL140',\n",
    "       'B0050', 'H0045', 'H0060', 'H0050', 'B0030', 'F0020', 'J0025', 'B0015',\n",
    "       'GL030', 'H0051', 'HCR', 'HDR', 'HRW', 'HSR', 'SHS',\n",
    "       'SHW', 'SR', 'SRS', 'SRS-W', 'ZLE', 'ZGK', 'ZLT', 'ZGP', 'total_steps', 'y']\n",
    "test = test[last_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"product_model\"], uniques = pd.factorize(test[\"product_model\"], sort=True)    \n",
    "shuffled = test.sample(frac=1)\n",
    "pivot = int(len(test) * .1)\n",
    "train = shuffled.iloc[pivot:].copy()\n",
    "val = shuffled.iloc[:pivot].copy()\n",
    "train = train.astype(float)\n",
    "val = val.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test.columns))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyDataset(Dataset):   \n",
    "  def __init__(self,data):     \n",
    "    super(MyDataset).__init__()\n",
    "    x=data.iloc[:,0:69].values\n",
    "    y=data.iloc[:,69].values     \n",
    "    self.x_train=torch.tensor(x,dtype=torch.float32).cuda()    \n",
    "    self.y_train=torch.tensor(y,dtype=torch.float32).view(-1, 1).cuda()    \n",
    " \n",
    "  def __len__(self):\n",
    "    return len(self.y_train)   \n",
    "  def __getitem__(self,idx):\n",
    "    return self.x_train[idx],self.y_train[idx]\n",
    " \n",
    "  def __len__(self):\n",
    "    return len(self.x_train)   \n",
    "  def __getitem__(self,idx):\n",
    "    return self.x_train[idx],self.y_train[idx]\n",
    "\n",
    "train_set=MyDataset(train)\n",
    "val_set=MyDataset(val)\n",
    "train_dl=DataLoader(train_set, batch_size=256, shuffle=True, num_workers=0)\n",
    "val_dl=DataLoader(val_set, batch_size=len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.mse_loss\n",
    "def fit(num_epochs, model, loss_fn, opt):\n",
    "    val_best  = 23\n",
    "    for epoch in range(num_epochs):        \n",
    "        for xb,yb in train_dl:            \n",
    "            pred = model(xb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        if epoch % 10 == 0:\n",
    "            loss_val = loss.item()\n",
    "            print(loss_val, epoch)            \n",
    "            for v_xb,v_yb in val_dl:\n",
    "                result = model(v_xb)     \n",
    "                val_err = torch.mean(abs(v_yb - result) / v_yb).item() * 100                    \n",
    "                print(\"val_err: \", val_err)\n",
    "            if val_err < val_best:\n",
    "                val_best = val_err\n",
    "                torch.save(model.state_dict(), f\"throttle_{str(val_err).replace('.', '_')[:5]}.pth\")\n",
    "    \n",
    "class SimpleNet(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(69, 512)                \n",
    "        self.linear2 = nn.Linear(512, 69)\n",
    "        self.linear3 = nn.Linear(69, 1)\n",
    "        \n",
    "        self.act1 = nn.ReLU() # Activation function        \n",
    "        self.act2 = nn.ReLU() # Activation function        \n",
    "        \n",
    "            \n",
    "    # Perform the computation\n",
    "    def forward(self, x):                \n",
    "        # x = self.linear1(x)\n",
    "        # x = self.act1(x)\n",
    "        # x = self.linear2(x)\n",
    "        # x = self.act2(x)\n",
    "        # x = self.linear3(x)\n",
    "        x1 = self.linear1(x)\n",
    "        x1_act = self.act1(x1)\n",
    "        x2 = self.linear2(x1_act)\n",
    "        x2_act = self.act2(x2) + x\n",
    "        x3 = self.linear3(x2_act)\n",
    "        return x3\n",
    "\n",
    "model = SimpleNet().cuda()\n",
    "opt = torch.optim.SGD(model.parameters(), 1e-6, momentum=0.9)\n",
    "fit(1000, model, loss_fn, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low_days = ['2021-07-03', '2021-07-04', '2021-07-10', '2021-07-11', '2021-07-17', '2021-07-18', '2021-07-24', '2021-07-25', '2021-07-31', '2021-08-01', '2021-08-07', '2021-08-08', '2021-08-14', '2021-08-15', '2021-08-21', '2021-08-22', '2021-08-28', '2021-08-29', '2021-09-04', '2021-09-05', '2021-09-11', '2021-09-12', '2021-09-18', '2021-09-19', '2021-09-25', '2021-09-26', '2021-10-02', '2021-10-03', '2021-10-09', '2021-10-10', '2021-10-16', '2021-10-17', '2021-10-23', '2021-10-24', '2021-10-30', '2021-10-31', '2021-11-06', '2021-11-07', '2021-11-13', '2021-11-14', '2021-11-20', '2021-11-21', '2021-11-27', '2021-11-28', '2021-12-04', '2021-12-05', '2021-12-11', '2021-12-12', '2021-12-18', '2021-12-19', '2021-12-25', '2021-12-26', '2021/06/05', '2021/06/06', '2021/06/13', '2021/06/19', '2021/06/20', '2021/06/27', '2021/06/30', '2021/07/02', '2021/07/03', '2021/07/04', '2021/07/05', '2021/07/11', '2021/07/17', '2021/07/18', '2021/07/25', '2021/07/31', '2021/08/01', '2021/08/08', '2021/08/14', '2021/08/15', '2021/08/22', '2021/08/28', '2021/08/29', '2021/09/04', '2021/09/05', '2021/09/06', '2021/09/12', '2021/09/18', '2021/09/19', '2021/09/26', '2021/10/02', '2021/10/03', '2021/10/10', '2021/10/16', '2021/10/17', '2021/10/24', '2021/10/30', '2021/10/31', '2021/11/07', '2021/11/13', '2021/11/14', '2021/11/21', '2021/11/25', '2021/11/26', '2021/11/27', '2021/11/28', '2021/12/05', '2021/12/11', '2021/12/12', '2021/12/19', '2021/12/23', '2021/12/24', '2021/12/25', '2021/12/26', '2021/12/31', '2022-01-01', '2022-01-02', '2022-01-08', '2022-01-09', '2022-01-15', '2022-01-16', '2022-01-22', '2022-01-23', '2022-01-29', '2022-01-30', '2022-02-05', '2022-02-06', '2022-02-12', '2022-02-13', '2022-02-19', '2022-02-20', '2022-02-26', '2022-02-27', '2022-03-05', '2022-03-06', '2022-03-12', '2022-03-13', '2022-03-19', '2022-03-20', '2022-03-26', '2022-03-27', '2022-04-02', '2022-04-03', '2022-04-09', '2022-04-10', '2022-04-16', '2022-04-17', '2022-04-23', '2022-04-24', '2022-04-30', '2022-05-01', '2022-05-07', '2022-05-08', '2022-05-14', '2022-05-15', '2022-05-21', '2022-05-22', '2022-05-28', '2022-05-29', '2022-06-04', '2022-06-05', '2022-06-11', '2022-06-12', '2022-06-18', '2022-06-19', '2022-06-25', '2022-06-26', '2022-07-02', '2022-07-03', '2022-07-09', '2022-07-10', '2022-07-16', '2022-07-17', '2022-07-23', '2022-07-24', '2022-07-30', '2022-07-31', '2022-08-06', '2022-08-07', '2022-08-13', '2022-08-14', '2022-08-20', '2022-08-21', '2022-08-27', '2022-08-28', '2022-09-03', '2022-09-04', '2022-09-10', '2022-09-11', '2022-09-17', '2022-09-18', '2022-09-24', '2022-09-25', '2022-10-01', '2022-10-02', '2022-10-08', '2022-10-09', '2022-10-15', '2022-10-16', '2022-10-22', '2022-10-23', '2022-10-29', '2022-10-30', '2022-11-05', '2022-11-06', '2022/01/01', '2022/01/02', '2022/01/03', '2022/01/08', '2022/01/09', '2022/01/16', '2022/01/22', '2022/01/23', '2022/01/30', '2022/02/04', '2022/02/05', '2022/02/06', '2022/02/13', '2022/02/19', '2022/02/20', '2022/02/27', '2022/03/05', '2022/03/06', '2022/03/12', '2022/03/13', '2022/03/19', '2022/03/20', '2022/03/27', '2022/04/02', '2022/04/03', '2022/04/10', '2022/04/15', '2022/04/16', '2022/04/17', '2022/04/23', '2022/04/24', '2022/04/30', '2022/05/01', '2022/05/08', '2022/05/14', '2022/05/15', '2022/05/22', '2022/05/28', '2022/05/29', '2022/05/30', '2022/06/05', '2022/06/11', '2022/06/12', '2022/06/18', '2022/06/19', '2022/06/25', '2022/06/26', '2022/06/30', '2022/07/02', '2022/07/03', '2022/07/04', '2022/07/05', '2022/07/10', '2022/07/16', '2022/07/17', '2022/07/23', '2022/07/24', '2022/07/30', '2022/07/31', '2022/08/06', '2022/08/07', '2022/08/13', '2022/08/14', '2022/08/20', '2022/08/21', '2022/08/27', '2022/08/28', '2022/09/03', '2022/09/04', '2022/09/05', '2022/09/10', '2022/09/11', '2022/09/17', '2022/09/18', '2022/09/24', '2022/09/25', '2022/10/01', '2022/10/02', '2022/10/08', '2022/10/09', '2022/10/15', '2022/10/16', '2022/10/22', '2022/10/23', '2022/10/29', '2022/10/30', '2022/11/05', '2022/11/06']\n",
    "# def f(mo):       \n",
    "#     mo_logs = vip_logs[vip_logs.order_number == mo].copy()\n",
    "#     mo_logs = mo_logs.drop_duplicates(subset=['sequence_code'], keep='first')\n",
    "#     mo_logs['diff'] = mo_logs['time_out'].diff(periods=1).astype('timedelta64[m]')\n",
    "#     mo_logs['start'] = mo_logs['time_out'].shift(1)    \n",
    "#     mo_logs.loc[mo_logs['diff'] > THROTTLE_MIN, 'diff'] = THROTTLE_MIN\n",
    "#     try:\n",
    "#         # for index, row in mo_logs.iloc[1:].iterrows():                \n",
    "#         #     if row['diff'] > THROTTLE_MIN:\n",
    "#         #         end = row.time_out.strftime(\"%Y-%m-%d\")\n",
    "#         #         start = row.start.strftime(\"%Y-%m-%d\")\n",
    "#         #         offday_count = len(list(x for x in low_days if start < x < end))             \n",
    "#         #         row['diff'] -= offday_count * 1440\n",
    "#         #         if row['diff'] > THROTTLE_MIN:\n",
    "#         #             # print(index)\n",
    "#         #             mo_logs.loc[index, 'diff'] = THROTTLE_MIN    \n",
    "#         period = mo_logs['diff'].sum() / 60\n",
    "#         # return mo, period, mo_logs.iloc[0]['time_out']\n",
    "#         return mo, period, len(mo_logs)\n",
    "#     except Exception as e: print(mo, e)\n",
    "\n",
    "# b_types = ['-III', '(GK)', '(GP)', '-II']\n",
    "# p_types = ['K','E','P','F','T','S','M','H']\n",
    "# for i in b_types:\n",
    "#     vip_orders[i] = 0\n",
    "# for i in p_types:\n",
    "#     vip_orders[i] = 0\n",
    "# vip_orders['custom'] = 0\n",
    "# for index, row in vip_orders.iterrows():\n",
    "#     try:\n",
    "#         des = row['item_description'].split(' RAIL')[0].split('L')[1]\n",
    "#         for bt in b_types:\n",
    "#             if bt in des:\n",
    "#                 vip_orders.loc[index, bt] = 1\n",
    "#                 des = des.replace(bt, '')\n",
    "#         print(des)\n",
    "#         for pt in p_types:\n",
    "#             if pt in des:            \n",
    "#                 vip_orders.loc[index, pt] = 1\n",
    "#     except Exception as e:\n",
    "#         vip_orders.loc[index, 'custom'] = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2690c4ade938f830d2b677a28d44942311eb5bf365c90b058b9292674ef26d09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
